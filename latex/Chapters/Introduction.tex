\chapter{Introduction}

\label{Introduction}

Neural networks designed for a classification task typically map inputs coming from a very high-dimensional space to a rather low-dimensional space - the space of possible classes.
$$
x \in \R^n,\ y \in \R^m ,\ n \gg m
$$
$$\phi (x) = y
$$
Given the nature of such a task, this forward process typically incurs in a huge loss of information. When $n > m$ and the data is not contained in some lower-dimensional submanifold, then the restriction of the map $\phi$ to the data manifold can not be bijective and therefore not invertible. 
Thus, given only the output, it is generally not possible to recover the input.
Typically, this transformation of the input to more abstract, meaningful features, along with the resulting compression is desired. Yet, the inverse problem of accurately modeling the posterior distribution $p(x|\;y)$ or an approximation thereof is an active area of research with many applications.
Such advantages of invertibility can be more efficient training, knowledge distillation in teacher-student networks, but also most notably, interpretability of a neural network's decision process - a big concern in security-related fields such as medical sciences, autonomous vehicles and face-recognition. 

Some recent work in this area are \textit{Invertible Neural Networks} \citep{ardizzone2018analyzing} , \textit{Glow: Generative Flow with Invertible 1x1 Convolutions} \citep{kingma2018glow} and \textit{Invertible Residual Networks} \citep{behrmann2018invertible}. The methods used vary from noise-optimization, direct parametrization to solving fixed-point iterations.

For the sake of interpretability, it is often enough to be able to sample from the posterior distribution.
The method that will be further examined in this work is an iterative refinement-process that optimizes random noise or an existing image to meet some criterion. This method was made popular by the computer vision program \textit{DeepDream} \citep{DeepDream} and later further improved on by \textit{DeepInversion} \citep{DeepInversion}.
