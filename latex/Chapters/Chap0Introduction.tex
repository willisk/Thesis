\chapter{Introduction}
% \label{chap:Intro}

%----------------------------------------------------------------------------------------
%	SECTION 1
%----------------------------------------------------------------------------------------


Deep neural networks have been successfully applied to
many areas that had previously been considered difficult to solve. 
Examples are 
 image classification (\cite{Image_recognition}), speech recognition (\cite{Speech_recognition}), 
natural language processing (\cite{gpt3}),
and reinforcement learning (\cite{AlphaZero}).
They have become a central part of machine learning
as a result of their versatility in application, state-of-the-art performance,
and their lack of need for designing handcrafted features.
Their success is largely attributed to an increase in large-scale publicly available
data sets and an increase in computing power.
However, applying models that have demonstrated their success in test scenarios 
to real-world environments presents new challenges, 
as often high-quality labeled data is not readily available for specific domains.

A routine assumption in machine learning is that data 
in the training and testing environment are identically distributed. 
In reality, data distributions may differ \cite{},
leading to performance degradations for models trained with 
standard deep learning algorithms \cite{}.
Fine-tuning the model to the new domain 
using the criterion-loss of the source task
is a straight-forward approach,
however this is prone to over-fitting when data is scarce in the target domain.

Transfer learning (\cite{XFER_SURVEY}) has recently emerged as a new field that is focused on 
transferring knowledge from machine-learning models which have learned to perform source task 
to a target task by exploiting commonalities in the tasks.
\cite{DA_how_transferable} has shown that 
this leads to improved results, even in divergent tasks.
% and first layers are general/transferrable features and later layers more task-specific
Given that the process of data set acquisition is generally a time-consuming and expensive process,
the importance of transfer learning is clear. 
Domain-adaptation (DA) in particular, a subtopic of transfer learning,
addresses the problem of a domain-mismatch for a source and target task.

A domain is considered to be a pair $(\set X, P)$ of an input space equipped with a probability distribution. DA operates under the assumption that the distributions over the input of source and target domain have changed.

In this work, the usual script on dealing with domain-adaptation is flipped: instead of fine-tuning the features of a deep learning model, the target data is transformed using information contained in the model features. 
A new variation of model inversion, called ..., is proposed and extensively tested against the baseline proposed by \cite{}. 
As a core contribution of this thesis, a comprehensive code base\footnote{\url{https://github.com/willisk/Thesis}} for domain adaptation experiments was built, allowing for detailed analysis of the proposed algorithms under varying configurations on real-world as well as toy data sets.
The results show that...

% \cite{GithubRepo}

\subsubsection{Related work}

The biggest challenge in domain-adaptation lies in measuring the difference in distributions
and in effectively bridging (addressing) this discrepancy.

Most related work domain adaptation 
aims to learn a domain-invariant feature-representation
which classic machine-learning methods can deal with.
In this effort, \cite{DA_AE} proposes training an auto-encoder that is able to model both domains.
\cite{DA_Deep_Transfer} makes use of the criterion loss along with a 
domain confusion loss 
which aims to make the learned representations indistinguishable between domains 
% an adaptation layer 
by maximally confusing a domain classifier.
(followup: \cite{DA_Confusion_MMD})
\cite{DA_MMD} further extends the idea use of adaptation layers to multiple layers.
\cite{Deep_Coral} formulates a distribution loss by using second-moment statistics, the covariances of features.
\cite{DA_CMD} proposes the Central Moment Discrepancy incorporating any number of higher-order moments.
Proves convergence for distributions of single features.
\cite{DA_Prototypes} proposes to classify data of target domain by comparing the feature-representations to
class-prototypes (a representative of each class).
\cite{DA_CycleGAN} learns explicit transformations from domain to domain, by proposing an adversarial loss
that measures the reconstruction accuracy.

\cite{IP_Deconv} and \cite{IP_VN} use deep neural networks for image debluring by learning



\subsubsection{Classification and Contribution of this Work}

\cite{DA_SURVEY} distinguishes the homogenous setting 
where $\set X_s$ and $\set X_t$, the source and target input space are the same,
but the distributions are different.
The approach in this work further makes use of both, 
a class-criterion,
where class labels are available in the new domain, while also using a 
statistics-criterion (\cite{DA_SURVEY}) that bridges the gap in distribution difference.
This work examines both, the unlabeled and the labeled setting.

\subsubsection{Contribution}

This work addresses domain adaptation by learning an explicit function mapping the 
source domain to target domain via residual networks.
This is in contrast to previously mentioned work, 
where the classifying neural network itself is changed 
in order to make features domain-invariant.
This comes with both, advantages and disadvantages.
Previously mentioned work assumes access to the source data set.
This work can make use of the statistics stored in batch-norm layers of the network.
Also, an explicit domain mapping function lets one further compare 
the result of the optimization to a ground truth.
This allows for additional evaluation metrics and a visual inspection.
This greatly simplifies evaluation success.

The class-dependent statistics loss introduced in \cref{chap:Background} can be seen as
matching statistics to a prototype as seen with \cite{DA_Prototypes}.

It uses a combination of a class-criterion and a statistics-criterion and 
explores the benefits of having a varying number of labeled data.

The unsupervised and supervised settings are compared.

This work can also be seen as contributing to the domain of inverse problems.
More specifically, the task of deblurring, deconvolution or image reconstruction.
Whereas other work, such as \cite{IP_Deconv} and \cite{IP_VN} train a deconvolution model on
reconstruction of handcrafted perturbation functions, 
this work makes use of the prior knowledge of a target data set
stored in an image classification network to correct for general distribution shifts.

An example use-case is given for distribution-shifts that occur over time.
Possible due to a changing environment or degrading sensors.
It can provide a method for adaptation/re-calibration.


Furthermore the data-privacy aspect of sharing these prototype information is considered.
This work was originally inspired by \cite{DeepInversion}, where noise is
optimized via a statistics-loss to match the source distribution.


\subsubsection{Outline}
\Cref{chap:Background} clears some mathematical preliminaries and establishes the notation 
used throughout. Furthermore, neural networks and, 
more specifically, convolutional neural networks are briefly introduced.
\Cref{chap:Objective} outlines the main objectives of this work and 
states the problem formally.
\Cref{chap:Experiments} explains in detail the experimental setup.
It introduces the various methods and the reconstruction and perturbation models.
Further, the data sets and the evaluation procedure is presented.
\Cref{chap:Results} presents the final results and conclusions.
